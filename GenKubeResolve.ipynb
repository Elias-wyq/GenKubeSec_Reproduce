{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4c93961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: å¯¼å…¥åº“ä¸è·¯å¾„é…ç½®\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "# è®¾ç½® Hugging Face å…¨å±€ç¼“å­˜ç›®å½•\n",
    "os.environ[\"HF_HOME\"] = \"/ssd_2t_1/wyq_workspace/hf_cache\"\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# --- é…ç½® ---\n",
    "# Mistral æ¨¡å‹è·¯å¾„ (å¦‚æœä½ å·²ç»ä¸‹è½½åˆ°æœ¬åœ°ï¼Œæ”¹æˆæœ¬åœ°è·¯å¾„ï¼›å¦åˆ™ä» HF æ‹‰å–)\n",
    "# è®ºæ–‡ä½¿ç”¨çš„æ˜¯ v0.2 Instruct ç‰ˆæœ¬\n",
    "MODEL_ID = \"mistralai/Mistral-7B-Instruct-v0.2\" \n",
    "\n",
    "# ä½ çš„ UMI æ˜ å°„æ–‡ä»¶ (Stage 1 äº§å‡º)\n",
    "# æ ¼å¼åº”è¯¥æ˜¯ CSV: ID, Description, ...\n",
    "UMI_CSV_PATH = \"/home/wyq/GenKubeSec_Reproduce/unify_error_umi/policies_with_remediation.csv\"\n",
    "\n",
    "# ä½ çš„æ£€æµ‹æ¨¡å‹è¾“å‡ºç»“æœ (Stage 2 äº§å‡ºï¼Œç”¨äºæµ‹è¯•)\n",
    "# å‡è®¾æ˜¯ä¸€ä¸ª jsonl æ–‡ä»¶ï¼ŒåŒ…å« filename, content, predicted_labels\n",
    "DETECTION_RESULT_PATH = \"/home/wyq/GenKubeSec_Reproduce/test_results_sample.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e319770b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸåŠ è½½ UMI æ˜ å°„ï¼Œå…± 165 æ¡è§„åˆ™ã€‚\n",
      "Indicates when a subject (Group/User/ServiceAccount) has create access to Pods. CIS Benchmark 5.1.4: The ability to create pods in a cluster opens up possibilities for privilege escalation and should be restricted, where possible.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: åŠ è½½ UMI æ˜ å°„è¡¨\n",
    "def load_umi_mapping(csv_path):\n",
    "    \"\"\"\n",
    "    å°† CSV åŠ è½½ä¸ºå­—å…¸: { \"52\": \"Image tag ':latest' used\", ... }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(UMI_CSV_PATH, dtype=str).fillna(\"\")\n",
    "        # å‡è®¾ CSV æœ‰ 'ID' å’Œ 'Checkov_Policy' (æˆ–è€…å…¶ä»–æè¿°åˆ—)\n",
    "        # è¿™é‡Œæˆ‘ä»¬ä¼˜å…ˆé€‰ä¸€ä¸ªæè¿°æœ€æ¸…æ¥šçš„åˆ—ï¼Œæˆ–è€…åˆå¹¶å‡ åˆ—\n",
    "        # è®ºæ–‡ä¸­æåˆ°ä½¿ç”¨ unified description\n",
    "        mapping = {}\n",
    "        for _, row in df.iterrows():\n",
    "            uid = row['ID']\n",
    "            # è¿™é‡Œç®€å•å– Checkov Policy ä½œä¸ºæè¿°ï¼Œä½ å¯ä»¥æ ¹æ®å®é™… CSV ç»“æ„è°ƒæ•´\n",
    "            # å¦‚æœä½ æœ‰ä¸“é—¨ç”Ÿæˆçš„ 'Description' åˆ—æ›´å¥½\n",
    "            desc = (\n",
    "                str(row.get('Checkov_Policy', '')).strip() or \n",
    "                str(row.get('Kube_Linter_Policy', '')).strip() or \n",
    "                str(row.get('Terrascan_Policy', '')).strip() or \n",
    "                str(row.get('Remediation', '')).strip()\n",
    "            )\n",
    "            mapping[uid] = desc\n",
    "        print(f\"âœ… æˆåŠŸåŠ è½½ UMI æ˜ å°„ï¼Œå…± {len(mapping)} æ¡è§„åˆ™ã€‚\")\n",
    "        return mapping\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ åŠ è½½ UMI å¤±è´¥: {e}\")\n",
    "        return {}\n",
    "\n",
    "umi_map = load_umi_mapping(UMI_CSV_PATH)\n",
    "\n",
    "# æµ‹è¯•ä¸€ä¸‹\n",
    "print(umi_map.get(\"113\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5747f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ æ­£åœ¨åŠ è½½ Mistral-7B-Instruct ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d176140ebabc488dab4ecf5304d144e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"http_proxy\"] = \"http://127.0.0.1:36217\"\n",
    "os.environ[\"https_proxy\"] = \"http://127.0.0.1:36217\"\n",
    "# Cell 4: åŠ è½½ Mistral-7B æ¨¡å‹\n",
    "print(\"ğŸš€ æ­£åœ¨åŠ è½½ Mistral-7B-Instruct ...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "\n",
    "# ä½¿ç”¨ 4-bit é‡åŒ–åŠ è½½ (é€Ÿåº¦å¿«ï¼Œæ˜¾å­˜å ç”¨æä½ï¼Œçº¦ 6GB)\n",
    "# å¦‚æœä½ æƒ³è¿½æ±‚æè‡´ç²¾åº¦ï¼Œå¯ä»¥å»æ‰ load_in_4bitï¼Œæ”¹ç”¨ torch_dtype=torch.float16\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True,  # éœ€è¦å®‰è£… bitsandbytes\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "print(\"âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc8926d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: æ”¹è¿›åçš„ Prompt ç”Ÿæˆå‡½æ•° (åŸºäºè®ºæ–‡é™„å½•)\n",
    "\n",
    "def construct_prompt(yaml_content, error_id, error_description):\n",
    "    \"\"\"\n",
    "    æ ¹æ® GenKubeSec è®ºæ–‡å¤ç° Prompt æ¨¡æ¿ã€‚\n",
    "    \n",
    "    å‚æ•°:\n",
    "    - yaml_content: å¾…æ£€æµ‹çš„ YAML æ–‡ä»¶å†…å®¹\n",
    "    - error_id: é”™è¯¯ ID (ä¾‹å¦‚ \"LLM_error_150\" æˆ– \"150\")\n",
    "    - error_description: é”™è¯¯æè¿° (ä¾‹å¦‚ \"Indicates when a deployment uses less than three replicas\")\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. ç¡®ä¿ error_id æ ¼å¼ä¸º LLM_error_<x>\n",
    "    # å¦‚æœä¼ å…¥çš„æ˜¯çº¯æ•°å­— \"150\"ï¼Œè‡ªåŠ¨è½¬ä¸º \"LLM_error_150\"\n",
    "    if not str(error_id).startswith(\"LLM_error_\"):\n",
    "        formatted_error_id = f\"LLM_error_{error_id}\"\n",
    "    else:\n",
    "        formatted_error_id = str(error_id)\n",
    "\n",
    "    # 2. ç³»ç»Ÿæç¤ºè¯ (System Prompt) - å®Œå…¨å¤åˆ»è®ºæ–‡å†…å®¹\n",
    "    system_instruction = f\"\"\"description: As a top DevOps engineer, you are provided with a K8s manifest that contains a misconfiguration labeled as {formatted_error_id}. Your tasks are:\n",
    "tasks:\n",
    "- Identify the line of the misconfiguration.\n",
    "- Provide the text of this line.\n",
    "- Offer reasoning for the identified misconfiguration only.\n",
    "- Suggest how to fix each identified misconfiguration.\n",
    "- Write the misconfiguration number corresponding to {formatted_error_id}.\n",
    "- Do not suggest a corrected version of the entire manifest.\n",
    "\n",
    "output format: \n",
    "The output must be a single, valid JSON object.\n",
    "Do not use Markdown code blocks.\n",
    "Ensure all keys and string values are enclosed in double quotes.\n",
    "\n",
    "IMPORTANT SYNTAX RULE:\n",
    "When writing YAML or JSON snippets inside the 'Remediation' field, YOU MUST USE SINGLE QUOTES (') for keys and values. NEVER use double quotes (\") inside the value string, as it breaks the JSON structure.\n",
    "Example: Use \"add: ['NET_BIND_SERVICE']\", NOT \"add: [\"NET_BIND_SERVICE\"]\".\n",
    "\n",
    "output example:\n",
    "{{\n",
    "    \"Line number\": \"The line number where the misconfiguration occurs.\",\n",
    "    \"Line text\": \"Text of the misconfiguration as it appears in the manifest.\",\n",
    "    \"Reasoning\": \"Explanation of why this misconfiguration occurs within the manifest.\",\n",
    "    \"Remediation\": \"Description of how to fix the misconfiguration.\",\n",
    "    \"Error number\": \"{formatted_error_id}\"\n",
    "}}\"\"\"\n",
    "\n",
    "    # 3. Few-Shot Examples (Q & A)\n",
    "    # è®ºæ–‡æ–‡æœ¬ä¸­åªæœ‰ Answerï¼Œè¿™é‡Œæˆ‘æ ¹æ® Answer æ‰‹åŠ¨è¡¥å…¨äº†å¯¹åº”çš„ Input YAML (Q)ï¼Œ\n",
    "    # è¿™æ ·æ¨¡å‹æ‰èƒ½å­¦ä¼š \"çœ‹åˆ°è¿™ä¸ªè¾“å…¥ -> è¾“å‡ºè¿™ä¸ªJSON\" çš„é€»è¾‘ã€‚\n",
    "    \n",
    "    few_shot_examples = \"\"\"\n",
    "Q:\n",
    "LLM_error_134: Indicates when objects use deprecated API versions under extensions/v1beta.\n",
    "KCF:\n",
    "apiVersion: extensions/v1beta1\n",
    "kind: Ingress\n",
    "metadata:\n",
    "  name: test-ingress\n",
    "\n",
    "A:\n",
    "{\n",
    "    \"Line number\": 1,\n",
    "    \"Line text\": \"apiVersion: extensions/v1beta1\",\n",
    "    \"Reasoning\": \"The API version 'extensions/v1beta1' for Ingress is deprecated and not supported in newer versions of K8s. Resources should use the current API version to ensure compatibility and access to the latest features.\",\n",
    "    \"Remediation\": \"Update the apiVersion from 'extensions/v1beta1' to 'networking.k8s.io/v1' for the Ingress resource. This change ensures compatibility with newer K8s versions and leverages the latest features and fixes.\",\n",
    "    \"Error number\": \"LLM_error_153\"\n",
    "}\n",
    "\n",
    "Q:\n",
    "LLM_error_18: The default namespace should not be used\n",
    "KCF:\n",
    "apiVersion: networking.k8s.io/v1\n",
    "kind: Ingress\n",
    "metadata:\n",
    "  name: gateway-ingress\n",
    "spec:\n",
    "  rules:\n",
    "  - http:\n",
    "      paths:\n",
    "      - path: /test\n",
    "        pathType: Prefix\n",
    "        backend:\n",
    "          service:\n",
    "            name: test\n",
    "            port:\n",
    "              number: 80\n",
    "\n",
    "A:\n",
    "{\n",
    "    \"Line number\": 4,\n",
    "    \"Line text\": \"name: gateway-ingress\",\n",
    "    \"Reasoning\": \"The resource 'gateway-ingress' does not specify a namespace and therefore defaults to the 'default' namespace. Using the default namespace for production or shared environments can lead to conflicts and security issues, as it is accessible by all users in a cluster.\",\n",
    "    \"Remediation\": \"Add a namespace to the metadata section of the Ingress resource to properly isolate resources and enhance security. For example, add 'namespace: custom-namespace' below the 'name' field.\",\n",
    "    \"Error number\": \"LLM_error_9\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "    # 4. å½“å‰ä»»åŠ¡ (Current Task)\n",
    "    current_task = f\"\"\"\n",
    "Q:\n",
    "{formatted_error_id}: {error_description}\n",
    "KCF:\n",
    "{yaml_content}\n",
    "\n",
    "A:\n",
    "\"\"\"\n",
    "    \n",
    "    # 5. ç»„åˆæœ€ç»ˆ Prompt\n",
    "    # Mistral æ ¼å¼: [INST] System + Examples + Task [/INST]\n",
    "    # æ³¨æ„ï¼šæˆ‘ä»¬æŠŠ System Prompt å’Œ Few-Shot éƒ½æ”¾åœ¨ INST é‡Œä½œä¸ºä¸Šä¸‹æ–‡\n",
    "    full_prompt = f\"[INST] {system_instruction}\\n\\n{few_shot_examples}\\n\\n{current_task} [/INST]\"\n",
    "    \n",
    "    return full_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "350a4f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: è§£æä¸æ¨ç†å‡½æ•°\n",
    "import json\n",
    "import re\n",
    "def parse_llm_output(output_text):\n",
    "    \"\"\"\n",
    "    ä» LLM çš„å›å¤ä¸­æå– JSONã€‚\n",
    "    LLM å¯èƒ½ä¼šåœ¨ JSON å‰åè¯´åºŸè¯ï¼Œéœ€è¦æ¸…æ´—ã€‚\n",
    "    \"\"\"\n",
    "    clean_text = output_text.strip()\n",
    "\n",
    "    # 1. å°è¯•å»é™¤ Markdown (```json ... ```)\n",
    "    match = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", clean_text, re.DOTALL)\n",
    "    if match:\n",
    "        clean_text = match.group(1)\n",
    "    # 2. æŸ¥æ‰¾æœ€å¤–å±‚çš„ {}\n",
    "    # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šä»å·¦è¾¹æ‰¾ç¬¬ä¸€ä¸ª {ï¼Œä»å³è¾¹æ‰¾æœ€åä¸€ä¸ª }\n",
    "    # åªè¦ Prompt è¢«æˆåŠŸå‰¥ç¦»ï¼Œè¿™ä¸ªé€»è¾‘å°±æ˜¯æ— æ•Œçš„\n",
    "    start = clean_text.find('{')\n",
    "    end = clean_text.rfind('}')\n",
    "    \n",
    "    if start != -1 and end != -1:\n",
    "        json_str = clean_text[start : end + 1]\n",
    "        def fix_nested_quotes(match):\n",
    "            prefix = match.group(1) # \"Remediation\": \"\n",
    "            content = match.group(2) # ä¸­é—´çš„ä¹±ä¸ƒå…«ç³Ÿçš„å†…å®¹\n",
    "            suffix = match.group(3) # \", \"Error number\"\n",
    "\n",
    "            # 1. æŠŠè½¬ä¹‰çš„åŒå¼•å· \\\" å˜æˆå•å¼•å· '\n",
    "            content = content.replace('\\\\\"', \"'\")\n",
    "            # 2. æŠŠå‰©ä¸‹çš„æ²¡è½¬ä¹‰çš„åŒå¼•å· \" ä¹Ÿå˜æˆå•å¼•å· '\n",
    "            content = content.replace('\"', \"'\")\n",
    "            \n",
    "            return f\"{prefix}{content}{suffix}\"\n",
    "\n",
    "        # æ­£åˆ™è§£é‡Šï¼š\n",
    "        # (\"Remediation\"\\s*:\\s*\")  -> æ•è·ç»„1: é”®åå¼€å¤´\n",
    "        # (.*?)                    -> æ•è·ç»„2: å†…å®¹ (éè´ªå©ªåŒ¹é…)\n",
    "        # (\"\\s*,\\s*\"Error number\") -> æ•è·ç»„3: ä¸‹ä¸€ä¸ªé”®å (ä½œä¸ºé”šç‚¹)\n",
    "        pattern = r'(\"Remediation\"\\s*:\\s*\")(.*?)(\"\\s*,\\s*\"Error number\")'\n",
    "        \n",
    "        # æ‰§è¡Œæ›¿æ¢ (flags=re.DOTALL è®© . èƒ½åŒ¹é…æ¢è¡Œç¬¦)\n",
    "        json_str = re.sub(pattern, fix_nested_quotes, json_str, flags=re.DOTALL)\n",
    "        json_str = json_str.replace('[\"', \"['\").replace('\"]', \"']\")\n",
    "\n",
    "        try:\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            return {\"error\": f\"JSONDecodeError: {str(e)}\", \"raw\": output_text}\n",
    "    else:\n",
    "        return {\"error\": \"No JSON braces found\", \"raw\": output_text}\n",
    "\n",
    "def genkube_resolve(yaml_content, detected_labels, model, tokenizer):\n",
    "    results = []\n",
    "    \n",
    "    for label in detected_labels:\n",
    "        # è§£ç æ ‡ç­¾: \"Deployment+52\" -> uid=\"52\"\n",
    "        parts = label.split('+')\n",
    "        if len(parts) != 2:\n",
    "            continue\n",
    "        \n",
    "        resource_kind, uid = parts\n",
    "        \n",
    "        # è·å–æè¿°\n",
    "        error_desc = umi_map.get(uid, \"Misconfiguration detected.\")\n",
    "        \n",
    "        print(f\"ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: {label} (ID: {uid})...\")\n",
    "        \n",
    "        # ä¼ å…¥ uid (ä¾‹å¦‚ \"52\")ï¼Œå‡½æ•°å†…éƒ¨ä¼šè‡ªåŠ¨è½¬ä¸º \"LLM_error_52\"\n",
    "        prompt = construct_prompt(yaml_content, uid, error_desc)\n",
    "        # ----------------\n",
    "        \n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        input_len = inputs.input_ids.shape[1]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                **inputs, \n",
    "                max_new_tokens=512,\n",
    "                do_sample=False, \n",
    "                pad_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        generated_ids = outputs[0][input_len:]\n",
    "        generated_text = tokenizer.decode(generated_ids, skip_special_tokens=True)\n",
    "        \n",
    "        # è§£æ JSON\n",
    "        analysis = parse_llm_output(generated_text)\n",
    "        if \"error\" in analysis:\n",
    "            # åªæœ‰å‡ºé”™æ—¶æ‰æ‰“å° rawï¼Œä¿æŒæ¸…çˆ½\n",
    "            print(f\"âš ï¸ è§£æå¤±è´¥ï¼æ¨¡å‹ç”Ÿæˆå†…å®¹:\\n{generated_text}\\n\" + \"-\"*20)\n",
    "        \n",
    "        results.append({\n",
    "            \"label\": label,\n",
    "            \"description\": error_desc,\n",
    "            \"analysis\": analysis\n",
    "        })\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6229ad81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ æ­£åœ¨åŠ è½½æ£€æµ‹æ¨¡å‹ GenKubeDetect (CodeT5p) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wyq/.conda/envs/genkubesect/lib/python3.13/site-packages/accelerate/utils/modeling.py:1598: UserWarning: The following device_map keys do not match any submodules in the model: ['decoder.embed_tokens']\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æ£€æµ‹æ¨¡å‹åŠ è½½å®Œæˆï¼ç°åœ¨æ˜¾å­˜é‡Œæœ‰ä¸¤ä¸ªæ¨¡å‹äº† (Mistral + CodeT5p)ã€‚\n"
     ]
    }
   ],
   "source": [
    "# Cell 7a: åŠ è½½ GenKubeDetect (æ£€æµ‹æ¨¡å‹)\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# --- é…ç½®æ£€æµ‹æ¨¡å‹è·¯å¾„ ---\n",
    "DETECT_BASE_PATH = \"/ssd_2t_1/wyq_workspace/genkubesect_structural_model\"\n",
    "DETECT_LORA_PATH = \"/ssd_2t_1/wyq_workspace/genkubesect_detection_model\"\n",
    "\n",
    "print(\"â³ æ­£åœ¨åŠ è½½æ£€æµ‹æ¨¡å‹ GenKubeDetect (CodeT5p) ...\")\n",
    "\n",
    "# 1. åŠ è½½ Tokenizer\n",
    "detect_tokenizer = AutoTokenizer.from_pretrained(DETECT_BASE_PATH, trust_remote_code=True)\n",
    "\n",
    "# 2. åŠ è½½åŸºç¡€æ¨¡å‹\n",
    "detect_base_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    DETECT_BASE_PATH,\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\" # è‡ªåŠ¨åˆ†é…åˆ° GPU\n",
    ")\n",
    "\n",
    "# 3. åŠ è½½ LoRA é€‚é…å™¨\n",
    "detect_model = PeftModel.from_pretrained(detect_base_model, DETECT_LORA_PATH)\n",
    "detect_model.eval()\n",
    "\n",
    "print(\"âœ… æ£€æµ‹æ¨¡å‹åŠ è½½å®Œæˆï¼ç°åœ¨æ˜¾å­˜é‡Œæœ‰ä¸¤ä¸ªæ¨¡å‹äº† (Mistral + CodeT5p)ã€‚\")\n",
    "\n",
    "def run_detection(yaml_content):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ GenKubeDetect æ¨¡å‹æ£€æµ‹ YAML\n",
    "    è¿”å›: åŸå§‹æ ‡ç­¾å­—ç¬¦ä¸² (e.g., \"Deployment+10, Service+52\")\n",
    "    \"\"\"\n",
    "    inputs = detect_tokenizer(\n",
    "        yaml_content, \n",
    "        return_tensors=\"pt\", \n",
    "        max_length=512, \n",
    "        truncation=True\n",
    "    ).to(detect_model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = detect_model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            max_new_tokens=128,\n",
    "            num_beams=5,\n",
    "            early_stopping=True\n",
    "        )\n",
    "    \n",
    "    return detect_tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "630f24b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "é˜¶æ®µ 1: GenKubeDetect (æ£€æµ‹ä¸­...)\n",
      "==================================================\n",
      "ğŸ“¥ æ¨¡å‹åŸå§‹è¾“å‡º: Deployment+10, Deployment+11, Deployment+112, Deployment+12, Deployment+13, Deployment+14, Deployment+15, Deployment+16, Deployment+160, Deployment+17, Deployment+18, Deployment+19, Deployment+27, Deployment+29, Deployment+30, Deployment+32, Deployment+33, Deployment+34, Deployment+35, Deployment+4, Deployment+48, Deployment+8\n",
      "è§£æåˆ°çš„æ ‡ç­¾ (22 ä¸ª): ['Deployment+33', 'Deployment+35', 'Deployment+16', 'Deployment+14', 'Deployment+12', 'Deployment+112', 'Deployment+27', 'Deployment+29', 'Deployment+160', 'Deployment+10', 'Deployment+11', 'Deployment+15', 'Deployment+19', 'Deployment+4', 'Deployment+13', 'Deployment+8', 'Deployment+32', 'Deployment+48', 'Deployment+30', 'Deployment+18', 'Deployment+17', 'Deployment+34']\n",
      "\n",
      "==================================================\n",
      "é˜¶æ®µ 2: GenKubeResolve (å®šä½ä¸ä¿®å¤ä¸­...)\n",
      "==================================================\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+33 (ID: 33)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+35 (ID: 35)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+16 (ID: 16)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+14 (ID: 14)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+12 (ID: 12)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+112 (ID: 112)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+27 (ID: 27)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+29 (ID: 29)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+160 (ID: 160)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+10 (ID: 10)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+11 (ID: 11)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+15 (ID: 15)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+19 (ID: 19)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+4 (ID: 4)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+13 (ID: 13)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+8 (ID: 8)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+32 (ID: 32)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+48 (ID: 48)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+30 (ID: 30)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+18 (ID: 18)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+17 (ID: 17)...\n",
      "ğŸ” æ­£åœ¨åˆ†æé”™è¯¯: Deployment+34 (ID: 34)...\n"
     ]
    }
   ],
   "source": [
    "# Cell 7b: è¿è¡Œå®Œæ•´æµæ°´çº¿ (Detect -> Resolve)\n",
    "\n",
    "# 1. å®šä¹‰å¾…æ£€æµ‹çš„ YAML (å°±æ˜¯ä½ ä¹‹å‰æä¾›çš„é‚£ä¸ªæœ‰é—®é¢˜çš„)\n",
    "target_yaml = \"\"\"\n",
    "apiVersion: apps/v1\n",
    "kind: Deployment\n",
    "metadata:\n",
    "  name: nginx-deployment\n",
    "spec:\n",
    "  selector:\n",
    "    matchLabels:\n",
    "      app: nginx\n",
    "  template:\n",
    "    metadata:\n",
    "      labels:\n",
    "        app: nginx\n",
    "    spec:\n",
    "      containers:\n",
    "      - name: nginx\n",
    "        image: nginx:latest\n",
    "        ports:\n",
    "        - containerPort: 80\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"é˜¶æ®µ 1: GenKubeDetect (æ£€æµ‹ä¸­...)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. è¿è¡Œæ£€æµ‹æ¨¡å‹\n",
    "raw_labels_str = run_detection(target_yaml)\n",
    "print(f\"ğŸ“¥ æ¨¡å‹åŸå§‹è¾“å‡º: {raw_labels_str}\")\n",
    "\n",
    "# 2. æ¸…æ´—æ ‡ç­¾ (String -> List)\n",
    "# ä½ çš„è¾“å‡ºç»“æœå¾ˆé•¿: \"Deployment+10, Deployment+11, ...\"\n",
    "# æˆ‘ä»¬éœ€è¦æŠŠå®ƒåˆ‡å‰²æˆåˆ—è¡¨ï¼Œå»é™¤ç©ºæ ¼\n",
    "if raw_labels_str.strip():\n",
    "    detected_labels = [label.strip() for label in raw_labels_str.split(',')]\n",
    "else:\n",
    "    detected_labels = []\n",
    "\n",
    "# å»é‡ (é˜²æ­¢æ¨¡å‹è¾“å‡ºé‡å¤æ ‡ç­¾)\n",
    "detected_labels = list(set(detected_labels))\n",
    "\n",
    "print(f\"è§£æåˆ°çš„æ ‡ç­¾ ({len(detected_labels)} ä¸ª): {detected_labels}\")\n",
    "\n",
    "# 3. å¦‚æœæ ‡ç­¾å¤ªå¤šï¼Œä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ï¼Œæˆ‘ä»¬å¯ä»¥åªå–å‰ 3 ä¸ª\n",
    "# å¦‚æœä½ æƒ³è·‘å®Œæ‰€æœ‰ 20 ä¸ªé”™è¯¯ï¼Œå¯ä»¥æŠŠä¸‹é¢è¿™ä¸¤è¡Œæ³¨é‡Šæ‰\n",
    "# if len(detected_labels) > 3:\n",
    "#     print(f\"é”™è¯¯å¤ªå¤šï¼Œä¸ºäº†èŠ‚çœæ—¶é—´ï¼Œä»…å±•ç¤ºå‰ 3 ä¸ªé”™è¯¯çš„ä¿®å¤æ–¹æ¡ˆ...\")\n",
    "#     detected_labels = detected_labels[:3]\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"é˜¶æ®µ 2: GenKubeResolve (å®šä½ä¸ä¿®å¤ä¸­...)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 4. è°ƒç”¨ Mistral è¿›è¡Œè§£é‡Š (ä½¿ç”¨ä¸Šä¸€æ®µä»£ç å®šä¹‰çš„ genkube_resolve)\n",
    "# æ³¨æ„ï¼šè¿™é‡Œå‡è®¾ä½ ä¹‹å‰çš„ Notebook å•å…ƒæ ¼é‡Œå·²ç»å®šä¹‰äº† `genkube_resolve`, `model` (Mistral) å’Œ `tokenizer` (Mistral)\n",
    "resolution_reports = genkube_resolve(target_yaml, detected_labels, model, tokenizer)\n",
    "# import json\n",
    "# print(json.dumps(resolution_reports, indent=2, ensure_ascii=False))\n",
    "# 5. æ‰“å°æœ€ç»ˆæŠ¥å‘Š\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"æœ€ç»ˆå®‰å…¨å®¡è®¡æŠ¥å‘Š\")\n",
    "# print(\"=\"*50)\n",
    "\n",
    "# for res in resolution_reports:\n",
    "#     print(f\"\\n[ID: {res['label']}]\")\n",
    "#     print(f\"è§„åˆ™æè¿°: {res['description']}\")\n",
    "    \n",
    "#     analysis = res['analysis']\n",
    "#     if \"error\" in analysis:\n",
    "#         print(f\"LLM è§£æ JSON å¤±è´¥: {analysis['error']}\")\n",
    "#     else:\n",
    "#         print(f\"è¡Œå·: {analysis.get('Line number') or analysis.get('line')}\")\n",
    "#         print(f\"åŸå› : {analysis.get('Reasoning') or analysis.get('reason')}\")\n",
    "#         print(f\"ä¿®å¤:\\n{analysis.get('Remediation') or analysis.get('fix')}\")\n",
    "#     print(\"-\" * 40)\n",
    "\n",
    "with open(DETECTION_RESULT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(resolution_reports, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genkubesect",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
